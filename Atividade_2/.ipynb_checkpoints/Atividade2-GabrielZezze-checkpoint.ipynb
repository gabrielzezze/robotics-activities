{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 2 - Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O entregável de toda esta atividade vai ser um código-fonte em C. \n",
    "\n",
    "Encorajamos vocês a fazerem vídeos demonstrando o resultado e a postar (pode ser privadamente) no YouTube\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você deve ter uma folha com o padrão anexo. \n",
    "*Dica:* Se não tiver, é possível fazer também com um tablet ou *smartphone*\n",
    " \n",
    "<img src=\"folha_atividade.jpeg\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time as t\n",
    "import sys\n",
    "import math\n",
    "import auxiliar as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webcam = cv2.VideoCapture(0)\n",
    "# val,image = webcam.read()\n",
    "# webcam.release()\n",
    "# plt.imshow(image)\n",
    "# cv2.imwrite(\"fotoFolha.png\",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - calibração\n",
    "\n",
    "Ouça a explicação do professor sobre o modelo de câmera *pinhole*  e desenhe a medida $f$ que separa o plano focal da pupila da câmera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distancia focal = 950.4950495049505\n"
     ]
    }
   ],
   "source": [
    "h0 = 10.1      # altura objeto #\n",
    "hi = 480       # altura objeto na camera(obtido em pixels pelo app da apple de visualizacao de imagems) #\n",
    "d = 20         # Distancia objeto ate a camera #\n",
    "f = (d*hi)/h0  # Distancia focal #\n",
    "print(\"distancia focal = {}\".format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter a distancia focal foi utilizado a equação : $$ H_i / f = H_0 / d $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "Modifique um dos exemplos `draw_circles_video.py` ou `videoplay.py` para passar a ler dados da webcam e identificar o círculo magenta e o círculo ciano, usando o `inRange`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "def mask(ImageBGR,color):\n",
    "    img_hsv = cv2.cvtColor(ImageBGR, cv2.COLOR_BGR2HSV)\n",
    "    hsv1, hsv2 = aux.ranges(str(color))\n",
    "    return cv2.inRange(img_hsv, hsv1, hsv2)\n",
    "\n",
    "while (True):\n",
    "    ret,frame = cap.read()\n",
    "    mask2 = cv2.bitwise_or(mask(frame,\"#8F3742\"),mask(frame,\"#193B6F\"))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=mask2)\n",
    "    segmentado_cor = cv2.morphologyEx(mask2,cv2.MORPH_CLOSE,np.ones((10, 10)))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=segmentado_cor)\n",
    "    cv2.imshow(\"Item 2\",selecao)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('z'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumindo que a folha se mantém sempre paralela ao plano de imagem da câmera, imprima a distância entre a folha e sua câmera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use when opening the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "def mask(ImageBGR,color):\n",
    "    img_hsv = cv2.cvtColor(ImageBGR, cv2.COLOR_BGR2HSV)\n",
    "    hsv1, hsv2 = aux.ranges(str(color))\n",
    "    return cv2.inRange(img_hsv, hsv1, hsv2)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    v = np.median(image)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    return edged\n",
    "\n",
    "while (True):\n",
    "    ret,frame = cap.read()\n",
    "    mask2 = cv2.bitwise_or(mask(frame,\"#8F3742\"),mask(frame,\"#193B6F\"))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=mask2)\n",
    "    segmentado_cor = cv2.morphologyEx(mask2,cv2.MORPH_CLOSE,np.ones((10, 10)))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=segmentado_cor)\n",
    "\n",
    "    gray = cv2.cvtColor(selecao, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    bordas = auto_canny(blur)\n",
    "    circles = []\n",
    "    bordas_color = cv2.cvtColor(bordas, cv2.COLOR_GRAY2BGR)\n",
    "    # HoughCircles - detects circles using the Hough Method#\n",
    "    circles = None\n",
    "    circles=cv2.HoughCircles(bordas,cv2.HOUGH_GRADIENT,2,40,param1=50,param2=100,minRadius=5,maxRadius=60)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0,:]:\n",
    "            cv2.circle(selecao,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "            cv2.circle(selecao,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "            if len(circles[0,:]) == 2:\n",
    "                circle1 = circles[0,0]\n",
    "                circle2 = circles[0,1]\n",
    "                cv2.line(selecao,(circle1[0],circle1[1]),(circle2[0],circle2[1]),(255,0,0),5)\n",
    "                x = abs(int(circle2[0]) - int(circle1[0]))\n",
    "                y = abs(int(circle2[1]) - int(circle1[1]))\n",
    "                hi = math.sqrt(x**2 + y**2)\n",
    "                if hi > 200:\n",
    "                    distancia = (10.1*950.5)/hi\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    if distancia > 5:\n",
    "                        cv2.putText(selecao,\"distancia entre camera e folha: {}\".format(distancia),(0,50), font, 0.6,(100,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Item 3\",selecao)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('z'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4\n",
    "\n",
    "Trace uma linha entre os centros do círculo magenta e do círculo ciano.\n",
    "\n",
    "Imprima na tela o ângulo entre esta linha e a horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use when opening the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "def mask(ImageBGR,color):\n",
    "    img_hsv = cv2.cvtColor(ImageBGR, cv2.COLOR_BGR2HSV)\n",
    "    hsv1, hsv2 = aux.ranges(str(color))\n",
    "    return cv2.inRange(img_hsv, hsv1, hsv2)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    v = np.median(image)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    return edged\n",
    "\n",
    "while (True):\n",
    "    ret,frame = cap.read()\n",
    "    mask2 = cv2.bitwise_or(mask(frame,\"#8F3742\"),mask(frame,\"#193B6F\"))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=mask2)\n",
    "    segmentado_cor = cv2.morphologyEx(mask2,cv2.MORPH_CLOSE,np.ones((10, 10)))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=segmentado_cor)\n",
    "\n",
    "    gray = cv2.cvtColor(selecao, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    bordas = auto_canny(blur)\n",
    "    circles = []\n",
    "    bordas_color = cv2.cvtColor(bordas, cv2.COLOR_GRAY2BGR)\n",
    "    # HoughCircles - detects circles using the Hough Method#\n",
    "    circles = None\n",
    "    circles=cv2.HoughCircles(bordas,cv2.HOUGH_GRADIENT,2,40,param1=50,param2=100,minRadius=10,maxRadius=50)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0,:]:\n",
    "            # print(i)\n",
    "            cv2.circle(selecao,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "            cv2.circle(selecao,(i[0],i[1]),2,(0,0,255),3)\n",
    "            if len(circles[0,:]) == 2:\n",
    "                circle1 = circles[0,0]\n",
    "                circle2 = circles[0,1]\n",
    "                cv2.line(selecao,(circle1[0],circle1[1]),(circle2[0],circle2[1]),(255,0,0),5)\n",
    "                x = abs(int(circle2[0]) - int(circle1[0]))\n",
    "                y = abs(int(circle2[1]) - int(circle1[1]))\n",
    "                if x > 0:\n",
    "                    angulo = math.atan(y/x)\n",
    "                if angulo > 0.1:\n",
    "                    print(\"Angulo entre reta e linha horizontal: {} radianos\".format(angulo))\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(selecao,\"   {0:.3f} radianos\".format(angulo),(0,50), font, 0.8,(50,50,255),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Item 4\",selecao)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('z'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5\n",
    "\n",
    "Usando transformada de Hough, desenhe um círculo sobre o círculo ciano e outro sobre o círculo magenta.\n",
    "\n",
    "**Desafio bônus**: ser capaz de eliminar circulos espúrios (aqueles que não são os da folha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use when opening the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "def mask(ImageBGR,color):\n",
    "    img_hsv = cv2.cvtColor(ImageBGR, cv2.COLOR_BGR2HSV)\n",
    "    hsv1, hsv2 = aux.ranges(str(color))\n",
    "    return cv2.inRange(img_hsv, hsv1, hsv2)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    v = np.median(image)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    return edged\n",
    "\n",
    "while (True):\n",
    "    ret,frame = cap.read()\n",
    "    mask2 = cv2.bitwise_or(mask(frame,\"#8F3742\"),mask(frame,\"#193B6F\"))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=mask2)\n",
    "    segmentado_cor = cv2.morphologyEx(mask2,cv2.MORPH_CLOSE,np.ones((10, 10)))\n",
    "    selecao = cv2.bitwise_and(frame,frame, mask=segmentado_cor)\n",
    "\n",
    "    gray = cv2.cvtColor(selecao, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    bordas = auto_canny(blur)\n",
    "    circles = []\n",
    "\n",
    "    bordas_color = cv2.cvtColor(bordas, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # HoughCircles - detects circles using the Hough Method#\n",
    "    circles = None\n",
    "    circles=cv2.HoughCircles(bordas,cv2.HOUGH_GRADIENT,2,40,param1=50,param2=100,minRadius=5,maxRadius=60)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0,:]:\n",
    "            print(i)\n",
    "            cv2.circle(selecao,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "            cv2.circle(selecao,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "    cv2.imshow(\"Item 5\",selecao)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('z'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6\n",
    "\n",
    "Usando `SIFT`, identifique o escrito *Insper* na folha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insper = cv2.imread('insper.png',0)\n",
    "insper_copy = insper.copy()\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kpts = sift.detect(insper_copy)\n",
    "x = [k.pt[0] for k in kpts]\n",
    "y = [k.pt[1] for k in kpts]\n",
    "# s will correspond to the neighborhood area\n",
    "s = [(k.size/2)**2 * math.pi for k in kpts]\n",
    "\n",
    "plt.scatter(x, y, s, c='r', alpha=0.1)\n",
    "plt.imshow(insper_copy, cmap=\"Greys_r\")\n",
    "plt.title('SIFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time as t\n",
    "import sys\n",
    "import math\n",
    "import auxiliar as aux\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Número mínimo de pontos correspondentes\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "img_original = cv2.imread(\"insper.png\",0) #Imagem a procurar\n",
    "\n",
    "while (True):\n",
    "    webcam = cv2.VideoCapture(0)\n",
    "    ret,frame = cap.read()\n",
    "    # frame = cv2.resize(frame,(300,225))\n",
    "    img_cena = frame  # Imagem do cenario - puxe do video para fazer isto\n",
    "    # Versões RGB das imagens, para plot\n",
    "    original_rgb = cv2.cvtColor(img_original, cv2.COLOR_GRAY2RGB)\n",
    "    cena_rgb = img_cena\n",
    "    # Imagem de saída\n",
    "    out = cena_rgb.copy()\n",
    "    # Cria o detector SIFT\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # Encontra os pontos únicos (keypoints) nas duas imagems\n",
    "    kp1, des1 = sift.detectAndCompute(img_original ,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img_cena,None)\n",
    "    # Configurações do algoritmo FLANN que compara keypoints e ver correspondências - não se preocupe com isso\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    # Configura o algoritmo de casamento de features que vê *como* o objeto que deve ser encontrado aparece na imagem\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    # Tenta fazer a melhor comparacao usando o algoritmo\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        # Separa os bons matches na origem e no destino\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        # Tenta achar uma trasformacao composta de rotacao, translacao e escala que situe uma imagem na outra\n",
    "        # Esta transformação é chamada de homografia\n",
    "        # Para saber mais veja\n",
    "        # https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        h,w = img_original.shape\n",
    "        # Um retângulo com as dimensões da imagem original\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        # Transforma os pontos do retângulo para onde estao na imagem destino usando a homografia encontrada\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "        # Desenha um contorno em vermelho ao redor de onde o objeto foi encontrado\n",
    "        img2b = cv2.polylines(out,[np.int32(dst)],True,(255,0,0),3, cv2.LINE_AA)\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "        matchesMask = None\n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                       singlePointColor = None,\n",
    "                       matchesMask = matchesMask, # draw only inliers\n",
    "                       flags = 2)\n",
    "\n",
    "    cv2.imshow(\"Item 6\",out)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('z'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
